{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from stdcnet import STDCNet1446, STDCNet813\n",
    "# from modules.bn import InPlaceABNSync as BatchNorm2d\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, ks=3, stride=1, padding=1, *args, **kwargs):\n",
    "        super(ConvBNReLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_chan,\n",
    "                out_chan,\n",
    "                kernel_size = ks,\n",
    "                stride = stride,\n",
    "                padding = padding,\n",
    "                bias = False)\n",
    "        # self.bn = BatchNorm2d(out_chan)\n",
    "        self.bn = BatchNorm2d(out_chan)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "\n",
    "class BiSeNetOutput(nn.Module):\n",
    "    def __init__(self, in_chan, mid_chan, n_classes, *args, **kwargs):\n",
    "        super(BiSeNetOutput, self).__init__()\n",
    "        self.conv = ConvBNReLU(in_chan, mid_chan, ks=1, stride=1, padding=0)\n",
    "        self.conv_out = nn.Conv2d(mid_chan, n_classes, kernel_size=1, bias=False)\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "    def get_params(self):\n",
    "        wd_params, nowd_params = [], []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "                wd_params.append(module.weight)\n",
    "                if not module.bias is None:\n",
    "                    nowd_params.append(module.bias)\n",
    "            elif isinstance(module, BatchNorm2d):\n",
    "                nowd_params += list(module.parameters())\n",
    "        return wd_params, nowd_params\n",
    "\n",
    "\n",
    "class AttentionRefinementModule(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
    "        super(AttentionRefinementModule, self).__init__()\n",
    "        self.conv = ConvBNReLU(in_chan, out_chan, ks=3, stride=1, padding=1)\n",
    "        self.conv_atten = nn.Conv2d(out_chan, out_chan, kernel_size= 1, bias=False)\n",
    "        # self.bn_atten = BatchNorm2d(out_chan)\n",
    "        self.bn_atten = BatchNorm2d(out_chan)\n",
    "\n",
    "        self.sigmoid_atten = nn.Sigmoid()\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.conv(x)\n",
    "        atten = F.avg_pool2d(feat, feat.size()[2:])\n",
    "        atten = self.conv_atten(atten)\n",
    "        atten = self.bn_atten(atten)\n",
    "        atten = self.sigmoid_atten(atten)\n",
    "        out = torch.mul(feat, atten)\n",
    "        return out\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "\n",
    "class ContextPath(nn.Module):\n",
    "    def __init__(self, backbone='CatNetSmall', pretrain_model='', use_conv_last=False, *args, **kwargs):\n",
    "        super(ContextPath, self).__init__()\n",
    "        \n",
    "        self.backbone_name = backbone\n",
    "        if backbone == 'STDCNet1446':\n",
    "            self.backbone = STDCNet1446(pretrain_model=pretrain_model, use_conv_last=use_conv_last)\n",
    "            self.arm16 = AttentionRefinementModule(512, 128)\n",
    "            inplanes = 1024\n",
    "            if use_conv_last:\n",
    "                inplanes = 1024\n",
    "            self.arm32 = AttentionRefinementModule(inplanes, 128)\n",
    "            self.conv_head32 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
    "            self.conv_head16 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
    "            self.conv_avg = ConvBNReLU(inplanes, 128, ks=1, stride=1, padding=0)\n",
    "\n",
    "        elif backbone == 'STDCNet813':\n",
    "            self.backbone = STDCNet813(pretrain_model=pretrain_model, use_conv_last=use_conv_last)\n",
    "            self.arm16 = AttentionRefinementModule(512, 128)\n",
    "            inplanes = 1024\n",
    "            if use_conv_last:\n",
    "                inplanes = 1024\n",
    "            self.arm32 = AttentionRefinementModule(inplanes, 128)\n",
    "            self.conv_head32 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
    "            self.conv_head16 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
    "            self.conv_avg = ConvBNReLU(inplanes, 128, ks=1, stride=1, padding=0)\n",
    "        else:\n",
    "            print(\"backbone is not in backbone lists\")\n",
    "            exit(0)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        H0, W0 = x.size()[2:]\n",
    "        print(\"input_size:\")\n",
    "        print(x.size())\n",
    "\n",
    "        feat2, feat4, feat8, feat16, feat32 = self.backbone(x)\n",
    "        print(\"after_backbone:feat2,feat4,feat8,feat16,feat32\")\n",
    "        print(feat2.size(),feat4.size(),feat8.size(),feat16.size(),feat32.size())\n",
    "        H8, W8 = feat8.size()[2:]\n",
    "        H16, W16 = feat16.size()[2:]\n",
    "        H32, W32 = feat32.size()[2:]\n",
    "        \n",
    "        avg = F.avg_pool2d(feat32, feat32.size()[2:])\n",
    "        print(\"after_avg:avg\")\n",
    "        print(avg.size())\n",
    "\n",
    "        avg = self.conv_avg(avg)\n",
    "        print(\"after_conv_avg:avg\")\n",
    "        print(avg.size())\n",
    "        \n",
    "        avg_up = F.interpolate(avg, (H32, W32), mode='nearest')\n",
    "        print(\"after_upsample1:avg_up\")\n",
    "        print(avg_up.size())\n",
    "\n",
    "\n",
    "        feat32_arm = self.arm32(feat32)\n",
    "        print(\"after_attention:feat32_arm\")\n",
    "        print(feat32_arm.size())\n",
    "        feat32_sum = feat32_arm + avg_up\n",
    "        print(\"after_sum:feat32_sum\")\n",
    "        print(feat32_sum.size())\n",
    "        feat32_up = F.interpolate(feat32_sum, (H16, W16), mode='nearest')\n",
    "        print(\"after_upsample2:feat32_up\")\n",
    "        print(feat32_up.size())\n",
    "        feat32_up = self.conv_head32(feat32_up)\n",
    "        print(\"after_conv_head32:feat32_up\")\n",
    "        print(feat32_up.size())\n",
    "\n",
    "        feat16_arm = self.arm16(feat16)\n",
    "        print(\"after_attention:feat16_arm\")\n",
    "        print(feat16_arm.size())\n",
    "        feat16_sum = feat16_arm + feat32_up\n",
    "        print(\"after_sum:feat16_sum\")\n",
    "        print(feat16_sum.size())\n",
    "        feat16_up = F.interpolate(feat16_sum, (H8, W8), mode='nearest')\n",
    "        print(\"after_upsample3:feat16_up\")\n",
    "        print(feat16_up.size())\n",
    "        feat16_up = self.conv_head16(feat16_up)\n",
    "        print(\"after_conv_head16:feat16_up\")\n",
    "        print(feat16_up.size())\n",
    "        print(\"contextpath end\")\n",
    "        \n",
    "        return feat2, feat4, feat8, feat16, feat16_up, feat32_up # x8, x16\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "    def get_params(self):\n",
    "        wd_params, nowd_params = [], []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "                wd_params.append(module.weight)\n",
    "                if not module.bias is None:\n",
    "                    nowd_params.append(module.bias)\n",
    "            elif isinstance(module, BatchNorm2d):\n",
    "                nowd_params += list(module.parameters())\n",
    "        return wd_params, nowd_params\n",
    "\n",
    "\n",
    "class FeatureFusionModule(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
    "        super(FeatureFusionModule, self).__init__()\n",
    "        self.convblk = ConvBNReLU(in_chan, out_chan, ks=1, stride=1, padding=0)\n",
    "        self.conv1 = nn.Conv2d(out_chan,\n",
    "                out_chan//4,\n",
    "                kernel_size = 1,\n",
    "                stride = 1,\n",
    "                padding = 0,\n",
    "                bias = False)\n",
    "        self.conv2 = nn.Conv2d(out_chan//4,\n",
    "                out_chan,\n",
    "                kernel_size = 1,\n",
    "                stride = 1,\n",
    "                padding = 0,\n",
    "                bias = False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, fsp, fcp):\n",
    "        fcat = torch.cat([fsp, fcp], dim=1)\n",
    "        feat = self.convblk(fcat)\n",
    "        atten = F.avg_pool2d(feat, feat.size()[2:])\n",
    "        atten = self.conv1(atten)\n",
    "        atten = self.relu(atten)\n",
    "        atten = self.conv2(atten)\n",
    "        atten = self.sigmoid(atten)\n",
    "        feat_atten = torch.mul(feat, atten)\n",
    "        feat_out = feat_atten + feat\n",
    "        return feat_out\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "    def get_params(self):\n",
    "        wd_params, nowd_params = [], []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "                wd_params.append(module.weight)\n",
    "                if not module.bias is None:\n",
    "                    nowd_params.append(module.bias)\n",
    "            elif isinstance(module, BatchNorm2d):\n",
    "                nowd_params += list(module.parameters())\n",
    "        return wd_params, nowd_params\n",
    "\n",
    "\n",
    "class BiSeNet(nn.Module):\n",
    "    def __init__(self, backbone, n_classes, pretrain_model='', use_boundary_2=False, use_boundary_4=False, use_boundary_8=False, use_boundary_16=False, use_conv_last=False, heat_map=False, *args, **kwargs):\n",
    "        super(BiSeNet, self).__init__()\n",
    "        \n",
    "        self.use_boundary_2 = use_boundary_2\n",
    "        self.use_boundary_4 = use_boundary_4\n",
    "        self.use_boundary_8 = use_boundary_8\n",
    "        self.use_boundary_16 = use_boundary_16\n",
    "        # self.heat_map = heat_map\n",
    "        self.cp = ContextPath(backbone, pretrain_model, use_conv_last=use_conv_last)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if backbone == 'STDCNet1446':\n",
    "            conv_out_inplanes = 128\n",
    "            sp2_inplanes = 32\n",
    "            sp4_inplanes = 64\n",
    "            sp8_inplanes = 256\n",
    "            sp16_inplanes = 512\n",
    "            inplane = sp8_inplanes + conv_out_inplanes\n",
    "\n",
    "        elif backbone == 'STDCNet813':\n",
    "            conv_out_inplanes = 128\n",
    "            sp2_inplanes = 32\n",
    "            sp4_inplanes = 64\n",
    "            sp8_inplanes = 256\n",
    "            sp16_inplanes = 512\n",
    "            inplane = sp8_inplanes + conv_out_inplanes\n",
    "\n",
    "        else:\n",
    "            print(\"backbone is not in backbone lists\")\n",
    "            exit(0)\n",
    "\n",
    "        self.ffm = FeatureFusionModule(inplane, 256)\n",
    "        self.conv_out = BiSeNetOutput(256, 64, n_classes)\n",
    "        self.conv_out16 = BiSeNetOutput(conv_out_inplanes, 64, n_classes)\n",
    "        self.conv_out32 = BiSeNetOutput(conv_out_inplanes, 64, n_classes)\n",
    "\n",
    "        self.conv_out_sp16 = BiSeNetOutput(sp16_inplanes, 64, 1)\n",
    "        \n",
    "        self.conv_out_sp8 = BiSeNetOutput(sp8_inplanes, 64, 1)\n",
    "        self.conv_out_sp4 = BiSeNetOutput(sp4_inplanes, 64, 1)\n",
    "        self.conv_out_sp2 = BiSeNetOutput(sp2_inplanes, 64, 1)\n",
    "        \n",
    "        self.conv_out_ajchan2 = ConvBNReLU(sp2_inplanes, n_classes, ks=3, stride=1, padding=1)\n",
    "        self.conv_out_ajchan4 = ConvBNReLU(sp4_inplanes, n_classes, ks=3, stride=1, padding=1)\n",
    "        \n",
    "#         self.CBR4 = ConvBNReLU(n_classes, n_classes, ks=3, stride=1, padding=1)\n",
    "#         self.CBR2 = ConvBNReLU(n_classes, n_classes, ks=3, stride=1, padding=1)\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = x.size()[2:]\n",
    "        \n",
    "        feat_res2, feat_res4, feat_res8, feat_res16, feat_cp8, feat_cp16 = self.cp(x)\n",
    "\n",
    "        feat_out_sp2 = self.conv_out_sp2(feat_res2)\n",
    "        print(\"feat_out_sp2:\")\n",
    "        print(feat_out_sp2.size())\n",
    "\n",
    "        feat_out_sp4 = self.conv_out_sp4(feat_res4)\n",
    "        print(\"feat_out_sp4:\")\n",
    "        print(feat_out_sp4.size())\n",
    "  \n",
    "        feat_out_sp8 = self.conv_out_sp8(feat_res8)\n",
    "        print(\"feat_out_sp8:\")\n",
    "        print(feat_out_sp8.size())\n",
    "\n",
    "        feat_out_sp16 = self.conv_out_sp16(feat_res16)\n",
    "        print(\"feat_out_sp16:\")\n",
    "        print(feat_out_sp16.size())\n",
    "\n",
    "        feat_fuse = self.ffm(feat_res8, feat_cp8)\n",
    "        print(\"feat_fuse:\")\n",
    "        print(feat_fuse.size())\n",
    "\n",
    "        \n",
    "        feat_out = self.conv_out(feat_fuse)\n",
    "        print(\"feat_out:\")\n",
    "        print(feat_out.size())\n",
    "        feat_out16 = self.conv_out16(feat_cp8)\n",
    "        print(\"feat_out16:\")\n",
    "        print(feat_out16.size())\n",
    "        feat_out32 = self.conv_out32(feat_cp16)\n",
    "        print(\"feat_out32:\")\n",
    "        print(feat_out32.size())\n",
    "        \n",
    "        feat_out = F.interpolate(feat_out, (H//4, W//4), mode='bilinear', align_corners=True)\n",
    "        feat_temp8 = feat_out+self.conv_out_ajchan4(feat_res4)\n",
    "        feat_out = F.interpolate(feat_temp8, (H//2, W//2), mode='bilinear', align_corners=True)\n",
    "        feat_temp8 = feat_out+self.conv_out_ajchan2(feat_res2)\n",
    "        feat_out = F.interpolate(feat_temp8, (H, W), mode='bilinear', align_corners=True)\n",
    "        print(\"after_upsample:feat_out:\")\n",
    "        print(feat_out.size())\n",
    "        \n",
    "        feat_out16 = F.interpolate(feat_out16, (H//4, W//4), mode='bilinear', align_corners=True)\n",
    "        feat_temp16 = feat_out16+self.conv_out_ajchan4(feat_res4)\n",
    "        feat_out = F.interpolate(feat_temp16, (H//2, W//2), mode='bilinear', align_corners=True)\n",
    "        feat_temp16 = feat_out+self.conv_out_ajchan2(feat_res2)\n",
    "        feat_out = F.interpolate(feat_temp16, (H, W), mode='bilinear', align_corners=True)\n",
    "        print(\"after_upsample:feat_out16:\")\n",
    "        print(feat_out.size())\n",
    "        \n",
    "        feat_out32 = F.interpolate(feat_out32, (H//4, W//4), mode='bilinear', align_corners=True)\n",
    "        feat_temp32 = feat_out32+self.conv_out_ajchan4(feat_res4)\n",
    "        feat_out = F.interpolate(feat_temp32, (H//2, W//2), mode='bilinear', align_corners=True)\n",
    "        feat_temp32 = feat_out+self.conv_out_ajchan2(feat_res2)\n",
    "        feat_out = F.interpolate(feat_temp32, (H, W), mode='bilinear', align_corners=True)\n",
    "        print(\"after_upsample:feat_out32:\")\n",
    "        print(feat_out.size())\n",
    "\n",
    "\n",
    "        if self.use_boundary_2 and self.use_boundary_4 and self.use_boundary_8:\n",
    "            return feat_out, feat_out16, feat_out32, feat_out_sp2, feat_out_sp4, feat_out_sp8\n",
    "        \n",
    "        if (not self.use_boundary_2) and self.use_boundary_4 and self.use_boundary_8:\n",
    "            return feat_out, feat_out16, feat_out32, feat_out_sp4, feat_out_sp8\n",
    "\n",
    "        if (not self.use_boundary_2) and (not self.use_boundary_4) and self.use_boundary_8:\n",
    "            return feat_out, feat_out16, feat_out32, feat_out_sp8\n",
    "        \n",
    "        if (not self.use_boundary_2) and (not self.use_boundary_4) and (not self.use_boundary_8):\n",
    "            return feat_out, feat_out16, feat_out32\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "    def get_params(self):\n",
    "        wd_params, nowd_params, lr_mul_wd_params, lr_mul_nowd_params = [], [], [], []\n",
    "        for name, child in self.named_children():\n",
    "            child_wd_params, child_nowd_params = child.get_params()\n",
    "            if isinstance(child, (FeatureFusionModule, BiSeNetOutput)):\n",
    "                lr_mul_wd_params += child_wd_params\n",
    "                lr_mul_nowd_params += child_nowd_params\n",
    "            else:\n",
    "                wd_params += child_wd_params\n",
    "                nowd_params += child_nowd_params\n",
    "        return wd_params, nowd_params, lr_mul_wd_params, lr_mul_nowd_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:\n",
      "torch.Size([1, 3, 768, 1536])\n",
      "feat4:\n",
      "torch.Size([1, 64, 192, 384])\n",
      "feat8:\n",
      "torch.Size([1, 256, 96, 192])\n",
      "feat16tmp:\n",
      "torch.Size([1, 256, 48, 96])\n",
      "feat16:\n",
      "torch.Size([1, 512, 48, 96])\n",
      "feat32:\n",
      "torch.Size([1, 1024, 24, 48])\n",
      "after_backbone:feat2,feat4,feat8,feat16,feat32\n",
      "torch.Size([1, 32, 384, 768]) torch.Size([1, 64, 192, 384]) torch.Size([1, 256, 96, 192]) torch.Size([1, 512, 48, 96]) torch.Size([1, 1024, 24, 48])\n",
      "after_avg:avg\n",
      "torch.Size([1, 1024, 1, 1])\n",
      "after_conv_avg:avg\n",
      "torch.Size([1, 128, 1, 1])\n",
      "after_upsample1:avg_up\n",
      "torch.Size([1, 128, 24, 48])\n",
      "after_attention:feat32_arm\n",
      "torch.Size([1, 128, 24, 48])\n",
      "after_sum:feat32_sum\n",
      "torch.Size([1, 128, 24, 48])\n",
      "after_upsample2:feat32_up\n",
      "torch.Size([1, 128, 48, 96])\n",
      "after_conv_head32:feat32_up\n",
      "torch.Size([1, 128, 48, 96])\n",
      "after_attention:feat16_arm\n",
      "torch.Size([1, 128, 48, 96])\n",
      "after_sum:feat16_sum\n",
      "torch.Size([1, 128, 48, 96])\n",
      "after_upsample3:feat16_up\n",
      "torch.Size([1, 128, 96, 192])\n",
      "after_conv_head16:feat16_up\n",
      "torch.Size([1, 128, 96, 192])\n",
      "contextpath end\n",
      "feat_out_sp2:\n",
      "torch.Size([1, 1, 384, 768])\n",
      "feat_out_sp4:\n",
      "torch.Size([1, 1, 192, 384])\n",
      "feat_out_sp8:\n",
      "torch.Size([1, 1, 96, 192])\n",
      "feat_out_sp16:\n",
      "torch.Size([1, 1, 48, 96])\n",
      "feat_fuse:\n",
      "torch.Size([1, 256, 96, 192])\n",
      "feat_out:\n",
      "torch.Size([1, 19, 96, 192])\n",
      "feat_out16:\n",
      "torch.Size([1, 19, 96, 192])\n",
      "feat_out32:\n",
      "torch.Size([1, 19, 48, 96])\n",
      "after_upsample:feat_out:\n",
      "torch.Size([1, 19, 768, 1536])\n",
      "after_upsample:feat_out16:\n",
      "torch.Size([1, 19, 768, 1536])\n",
      "after_upsample:feat_out32:\n",
      "torch.Size([1, 19, 768, 1536])\n",
      "torch.Size([1, 19, 768, 1536])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    net = BiSeNet('STDCNet1446', 19)\n",
    "#     net.cuda()\n",
    "    net.eval()\n",
    "    in_ten = torch.randn(1, 3, 768, 1536)\n",
    "    out, out16, out32 = net(in_ten)\n",
    "    print(out.shape)\n",
    "    torch.save(net.state_dict(), 'STDCNet1446_modify_conv1layeradd.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-313bc1cd1555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseblock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, block_num=3, stride=1):\n",
    "        super(CatBottleneck, self).__init__()\n",
    "        self.conv_list = nn.ModuleList()\n",
    "        \n",
    "        for idx in range(block_num):\n",
    "            if idx == 0:\n",
    "                self.conv_list.append(ConvX(in_planes, out_planes//2, kernel=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3X(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel=3, stride=1):\n",
    "        super(Conv3X, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel, stride=stride, padding=kernel//2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "class Conv1X(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.],\n",
      "          [ 9., 10., 11.]],\n",
      "\n",
      "         [[12., 13., 14.],\n",
      "          [15., 16., 17.],\n",
      "          [18., 19., 20.],\n",
      "          [21., 22., 23.]]]])\n",
      "x_mean1:\n",
      "tensor([[[[ 6.,  7.,  8.],\n",
      "          [ 9., 10., 11.],\n",
      "          [12., 13., 14.],\n",
      "          [15., 16., 17.]]]])\n",
      "torch.Size([1, 1, 4, 3])\n",
      "x_mean:\n",
      "tensor(11.5000)\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(24).view(1,2,4,3)\n",
    "'''\n",
    "注意：在这里使用的时候转一下类型，否则会报RuntimeError: Can only calculate the mean of floating types. Got Long instead.的错误。\n",
    "查看了一下x元素类型是torch.int64,根据提示添加一句x=x.float()转为tensor.float32就行\n",
    "'''\n",
    "x=x.float()\n",
    "x_mean=torch.mean(x)\n",
    "# x_mean0=torch.mean(x,dim=0,keepdim=True)\n",
    "x_mean1=torch.mean(x,dim=1,keepdim=True)\n",
    "print('x:')\n",
    "print(x)\n",
    "# print('x_mean0:')\n",
    "# print(x_mean0)\n",
    "print('x_mean1:')\n",
    "print(x_mean1)\n",
    "print(x_mean1.size())\n",
    "print('x_mean:')\n",
    "print(x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.conv.weight\n",
      "features.0.bn.weight\n",
      "features.0.bn.bias\n",
      "features.0.bn.running_mean\n",
      "features.0.bn.running_var\n",
      "features.0.bn.num_batches_tracked\n",
      "features.1.conv.weight\n",
      "features.1.bn.weight\n",
      "features.1.bn.bias\n",
      "features.1.bn.running_mean\n",
      "features.1.bn.running_var\n",
      "features.1.bn.num_batches_tracked\n",
      "features.2.conv_list.0.conv.weight\n",
      "features.2.conv_list.0.bn.weight\n",
      "features.2.conv_list.0.bn.bias\n",
      "features.2.conv_list.0.bn.running_mean\n",
      "features.2.conv_list.0.bn.running_var\n",
      "features.2.conv_list.0.bn.num_batches_tracked\n",
      "features.2.conv_list.1.conv.weight\n",
      "features.2.conv_list.1.bn.weight\n",
      "features.2.conv_list.1.bn.bias\n",
      "features.2.conv_list.1.bn.running_mean\n",
      "features.2.conv_list.1.bn.running_var\n",
      "features.2.conv_list.1.bn.num_batches_tracked\n",
      "features.2.conv_list.2.conv.weight\n",
      "features.2.conv_list.2.bn.weight\n",
      "features.2.conv_list.2.bn.bias\n",
      "features.2.conv_list.2.bn.running_mean\n",
      "features.2.conv_list.2.bn.running_var\n",
      "features.2.conv_list.2.bn.num_batches_tracked\n",
      "features.2.conv_list.3.conv.weight\n",
      "features.2.conv_list.3.bn.weight\n",
      "features.2.conv_list.3.bn.bias\n",
      "features.2.conv_list.3.bn.running_mean\n",
      "features.2.conv_list.3.bn.running_var\n",
      "features.2.conv_list.3.bn.num_batches_tracked\n",
      "features.2.atenchannal2.conv1.weight\n",
      "features.2.avd_layer.0.weight\n",
      "features.2.avd_layer.1.weight\n",
      "features.2.avd_layer.1.bias\n",
      "features.2.avd_layer.1.running_mean\n",
      "features.2.avd_layer.1.running_var\n",
      "features.2.avd_layer.1.num_batches_tracked\n",
      "features.2.conavg_layer.weight\n",
      "features.2.conavg_layer_BN.weight\n",
      "features.2.conavg_layer_BN.bias\n",
      "features.2.conavg_layer_BN.running_mean\n",
      "features.2.conavg_layer_BN.running_var\n",
      "features.2.conavg_layer_BN.num_batches_tracked\n",
      "features.3.conv_list.0.conv.weight\n",
      "features.3.conv_list.0.bn.weight\n",
      "features.3.conv_list.0.bn.bias\n",
      "features.3.conv_list.0.bn.running_mean\n",
      "features.3.conv_list.0.bn.running_var\n",
      "features.3.conv_list.0.bn.num_batches_tracked\n",
      "features.3.conv_list.1.conv.weight\n",
      "features.3.conv_list.1.bn.weight\n",
      "features.3.conv_list.1.bn.bias\n",
      "features.3.conv_list.1.bn.running_mean\n",
      "features.3.conv_list.1.bn.running_var\n",
      "features.3.conv_list.1.bn.num_batches_tracked\n",
      "features.3.conv_list.2.conv.weight\n",
      "features.3.conv_list.2.bn.weight\n",
      "features.3.conv_list.2.bn.bias\n",
      "features.3.conv_list.2.bn.running_mean\n",
      "features.3.conv_list.2.bn.running_var\n",
      "features.3.conv_list.2.bn.num_batches_tracked\n",
      "features.3.conv_list.3.conv.weight\n",
      "features.3.conv_list.3.bn.weight\n",
      "features.3.conv_list.3.bn.bias\n",
      "features.3.conv_list.3.bn.running_mean\n",
      "features.3.conv_list.3.bn.running_var\n",
      "features.3.conv_list.3.bn.num_batches_tracked\n",
      "features.3.atenchannal2.conv1.weight\n",
      "features.3.conavg_layer.weight\n",
      "features.3.conavg_layer_BN.weight\n",
      "features.3.conavg_layer_BN.bias\n",
      "features.3.conavg_layer_BN.running_mean\n",
      "features.3.conavg_layer_BN.running_var\n",
      "features.3.conavg_layer_BN.num_batches_tracked\n",
      "features.4.conv_list.0.conv.weight\n",
      "features.4.conv_list.0.bn.weight\n",
      "features.4.conv_list.0.bn.bias\n",
      "features.4.conv_list.0.bn.running_mean\n",
      "features.4.conv_list.0.bn.running_var\n",
      "features.4.conv_list.0.bn.num_batches_tracked\n",
      "features.4.conv_list.1.conv.weight\n",
      "features.4.conv_list.1.bn.weight\n",
      "features.4.conv_list.1.bn.bias\n",
      "features.4.conv_list.1.bn.running_mean\n",
      "features.4.conv_list.1.bn.running_var\n",
      "features.4.conv_list.1.bn.num_batches_tracked\n",
      "features.4.conv_list.2.conv.weight\n",
      "features.4.conv_list.2.bn.weight\n",
      "features.4.conv_list.2.bn.bias\n",
      "features.4.conv_list.2.bn.running_mean\n",
      "features.4.conv_list.2.bn.running_var\n",
      "features.4.conv_list.2.bn.num_batches_tracked\n",
      "features.4.conv_list.3.conv.weight\n",
      "features.4.conv_list.3.bn.weight\n",
      "features.4.conv_list.3.bn.bias\n",
      "features.4.conv_list.3.bn.running_mean\n",
      "features.4.conv_list.3.bn.running_var\n",
      "features.4.conv_list.3.bn.num_batches_tracked\n",
      "features.4.atenchannal2.conv1.weight\n",
      "features.4.conavg_layer.weight\n",
      "features.4.conavg_layer_BN.weight\n",
      "features.4.conavg_layer_BN.bias\n",
      "features.4.conavg_layer_BN.running_mean\n",
      "features.4.conavg_layer_BN.running_var\n",
      "features.4.conavg_layer_BN.num_batches_tracked\n",
      "features.5.conv_list.0.conv.weight\n",
      "features.5.conv_list.0.bn.weight\n",
      "features.5.conv_list.0.bn.bias\n",
      "features.5.conv_list.0.bn.running_mean\n",
      "features.5.conv_list.0.bn.running_var\n",
      "features.5.conv_list.0.bn.num_batches_tracked\n",
      "features.5.conv_list.1.conv.weight\n",
      "features.5.conv_list.1.bn.weight\n",
      "features.5.conv_list.1.bn.bias\n",
      "features.5.conv_list.1.bn.running_mean\n",
      "features.5.conv_list.1.bn.running_var\n",
      "features.5.conv_list.1.bn.num_batches_tracked\n",
      "features.5.conv_list.2.conv.weight\n",
      "features.5.conv_list.2.bn.weight\n",
      "features.5.conv_list.2.bn.bias\n",
      "features.5.conv_list.2.bn.running_mean\n",
      "features.5.conv_list.2.bn.running_var\n",
      "features.5.conv_list.2.bn.num_batches_tracked\n",
      "features.5.conv_list.3.conv.weight\n",
      "features.5.conv_list.3.bn.weight\n",
      "features.5.conv_list.3.bn.bias\n",
      "features.5.conv_list.3.bn.running_mean\n",
      "features.5.conv_list.3.bn.running_var\n",
      "features.5.conv_list.3.bn.num_batches_tracked\n",
      "features.5.atenchannal2.conv1.weight\n",
      "features.5.conavg_layer.weight\n",
      "features.5.conavg_layer_BN.weight\n",
      "features.5.conavg_layer_BN.bias\n",
      "features.5.conavg_layer_BN.running_mean\n",
      "features.5.conavg_layer_BN.running_var\n",
      "features.5.conavg_layer_BN.num_batches_tracked\n",
      "features.6.conv_list.0.conv.weight\n",
      "features.6.conv_list.0.bn.weight\n",
      "features.6.conv_list.0.bn.bias\n",
      "features.6.conv_list.0.bn.running_mean\n",
      "features.6.conv_list.0.bn.running_var\n",
      "features.6.conv_list.0.bn.num_batches_tracked\n",
      "features.6.conv_list.1.conv.weight\n",
      "features.6.conv_list.1.bn.weight\n",
      "features.6.conv_list.1.bn.bias\n",
      "features.6.conv_list.1.bn.running_mean\n",
      "features.6.conv_list.1.bn.running_var\n",
      "features.6.conv_list.1.bn.num_batches_tracked\n",
      "features.6.conv_list.2.conv.weight\n",
      "features.6.conv_list.2.bn.weight\n",
      "features.6.conv_list.2.bn.bias\n",
      "features.6.conv_list.2.bn.running_mean\n",
      "features.6.conv_list.2.bn.running_var\n",
      "features.6.conv_list.2.bn.num_batches_tracked\n",
      "features.6.conv_list.3.conv.weight\n",
      "features.6.conv_list.3.bn.weight\n",
      "features.6.conv_list.3.bn.bias\n",
      "features.6.conv_list.3.bn.running_mean\n",
      "features.6.conv_list.3.bn.running_var\n",
      "features.6.conv_list.3.bn.num_batches_tracked\n",
      "features.6.atenchannal2.conv1.weight\n",
      "features.6.conavg_layer.weight\n",
      "features.6.conavg_layer_BN.weight\n",
      "features.6.conavg_layer_BN.bias\n",
      "features.6.conavg_layer_BN.running_mean\n",
      "features.6.conavg_layer_BN.running_var\n",
      "features.6.conavg_layer_BN.num_batches_tracked\n",
      "features.7.conv_list.0.conv.weight\n",
      "features.7.conv_list.0.bn.weight\n",
      "features.7.conv_list.0.bn.bias\n",
      "features.7.conv_list.0.bn.running_mean\n",
      "features.7.conv_list.0.bn.running_var\n",
      "features.7.conv_list.0.bn.num_batches_tracked\n",
      "features.7.conv_list.1.conv.weight\n",
      "features.7.conv_list.1.bn.weight\n",
      "features.7.conv_list.1.bn.bias\n",
      "features.7.conv_list.1.bn.running_mean\n",
      "features.7.conv_list.1.bn.running_var\n",
      "features.7.conv_list.1.bn.num_batches_tracked\n",
      "features.7.conv_list.2.conv.weight\n",
      "features.7.conv_list.2.bn.weight\n",
      "features.7.conv_list.2.bn.bias\n",
      "features.7.conv_list.2.bn.running_mean\n",
      "features.7.conv_list.2.bn.running_var\n",
      "features.7.conv_list.2.bn.num_batches_tracked\n",
      "features.7.atenchannal2.conv1.weight\n",
      "features.7.conavg_layer.weight\n",
      "features.7.conavg_layer_BN.weight\n",
      "features.7.conavg_layer_BN.bias\n",
      "features.7.conavg_layer_BN.running_mean\n",
      "features.7.conavg_layer_BN.running_var\n",
      "features.7.conavg_layer_BN.num_batches_tracked\n",
      "features.8.conv_list.0.conv.weight\n",
      "features.8.conv_list.0.bn.weight\n",
      "features.8.conv_list.0.bn.bias\n",
      "features.8.conv_list.0.bn.running_mean\n",
      "features.8.conv_list.0.bn.running_var\n",
      "features.8.conv_list.0.bn.num_batches_tracked\n",
      "features.8.conv_list.1.conv.weight\n",
      "features.8.conv_list.1.bn.weight\n",
      "features.8.conv_list.1.bn.bias\n",
      "features.8.conv_list.1.bn.running_mean\n",
      "features.8.conv_list.1.bn.running_var\n",
      "features.8.conv_list.1.bn.num_batches_tracked\n",
      "features.8.conv_list.2.conv.weight\n",
      "features.8.conv_list.2.bn.weight\n",
      "features.8.conv_list.2.bn.bias\n",
      "features.8.conv_list.2.bn.running_mean\n",
      "features.8.conv_list.2.bn.running_var\n",
      "features.8.conv_list.2.bn.num_batches_tracked\n",
      "features.8.conv_list.3.conv.weight\n",
      "features.8.conv_list.3.bn.weight\n",
      "features.8.conv_list.3.bn.bias\n",
      "features.8.conv_list.3.bn.running_mean\n",
      "features.8.conv_list.3.bn.running_var\n",
      "features.8.conv_list.3.bn.num_batches_tracked\n",
      "features.8.atenchannal2.conv1.weight\n",
      "features.8.avd_layer.0.weight\n",
      "features.8.avd_layer.1.weight\n",
      "features.8.avd_layer.1.bias\n",
      "features.8.avd_layer.1.running_mean\n",
      "features.8.avd_layer.1.running_var\n",
      "features.8.avd_layer.1.num_batches_tracked\n",
      "features.8.conavg_layer.weight\n",
      "features.8.conavg_layer_BN.weight\n",
      "features.8.conavg_layer_BN.bias\n",
      "features.8.conavg_layer_BN.running_mean\n",
      "features.8.conavg_layer_BN.running_var\n",
      "features.8.conavg_layer_BN.num_batches_tracked\n",
      "features.9.conv_list.0.conv.weight\n",
      "features.9.conv_list.0.bn.weight\n",
      "features.9.conv_list.0.bn.bias\n",
      "features.9.conv_list.0.bn.running_mean\n",
      "features.9.conv_list.0.bn.running_var\n",
      "features.9.conv_list.0.bn.num_batches_tracked\n",
      "features.9.conv_list.1.conv.weight\n",
      "features.9.conv_list.1.bn.weight\n",
      "features.9.conv_list.1.bn.bias\n",
      "features.9.conv_list.1.bn.running_mean\n",
      "features.9.conv_list.1.bn.running_var\n",
      "features.9.conv_list.1.bn.num_batches_tracked\n",
      "features.9.conv_list.2.conv.weight\n",
      "features.9.conv_list.2.bn.weight\n",
      "features.9.conv_list.2.bn.bias\n",
      "features.9.conv_list.2.bn.running_mean\n",
      "features.9.conv_list.2.bn.running_var\n",
      "features.9.conv_list.2.bn.num_batches_tracked\n",
      "features.9.conv_list.3.conv.weight\n",
      "features.9.conv_list.3.bn.weight\n",
      "features.9.conv_list.3.bn.bias\n",
      "features.9.conv_list.3.bn.running_mean\n",
      "features.9.conv_list.3.bn.running_var\n",
      "features.9.conv_list.3.bn.num_batches_tracked\n",
      "features.9.atenchannal2.conv1.weight\n",
      "features.9.conavg_layer.weight\n",
      "features.9.conavg_layer_BN.weight\n",
      "features.9.conavg_layer_BN.bias\n",
      "features.9.conavg_layer_BN.running_mean\n",
      "features.9.conavg_layer_BN.running_var\n",
      "features.9.conavg_layer_BN.num_batches_tracked\n",
      "features.10.conv_list.0.conv.weight\n",
      "features.10.conv_list.0.bn.weight\n",
      "features.10.conv_list.0.bn.bias\n",
      "features.10.conv_list.0.bn.running_mean\n",
      "features.10.conv_list.0.bn.running_var\n",
      "features.10.conv_list.0.bn.num_batches_tracked\n",
      "features.10.conv_list.1.conv.weight\n",
      "features.10.conv_list.1.bn.weight\n",
      "features.10.conv_list.1.bn.bias\n",
      "features.10.conv_list.1.bn.running_mean\n",
      "features.10.conv_list.1.bn.running_var\n",
      "features.10.conv_list.1.bn.num_batches_tracked\n",
      "features.10.conv_list.2.conv.weight\n",
      "features.10.conv_list.2.bn.weight\n",
      "features.10.conv_list.2.bn.bias\n",
      "features.10.conv_list.2.bn.running_mean\n",
      "features.10.conv_list.2.bn.running_var\n",
      "features.10.conv_list.2.bn.num_batches_tracked\n",
      "features.10.conv_list.3.conv.weight\n",
      "features.10.conv_list.3.bn.weight\n",
      "features.10.conv_list.3.bn.bias\n",
      "features.10.conv_list.3.bn.running_mean\n",
      "features.10.conv_list.3.bn.running_var\n",
      "features.10.conv_list.3.bn.num_batches_tracked\n",
      "features.10.atenchannal2.conv1.weight\n",
      "features.10.conavg_layer.weight\n",
      "features.10.conavg_layer_BN.weight\n",
      "features.10.conavg_layer_BN.bias\n",
      "features.10.conavg_layer_BN.running_mean\n",
      "features.10.conavg_layer_BN.running_var\n",
      "features.10.conavg_layer_BN.num_batches_tracked\n",
      "features.11.conv_list.0.conv.weight\n",
      "features.11.conv_list.0.bn.weight\n",
      "features.11.conv_list.0.bn.bias\n",
      "features.11.conv_list.0.bn.running_mean\n",
      "features.11.conv_list.0.bn.running_var\n",
      "features.11.conv_list.0.bn.num_batches_tracked\n",
      "features.11.conv_list.1.conv.weight\n",
      "features.11.conv_list.1.bn.weight\n",
      "features.11.conv_list.1.bn.bias\n",
      "features.11.conv_list.1.bn.running_mean\n",
      "features.11.conv_list.1.bn.running_var\n",
      "features.11.conv_list.1.bn.num_batches_tracked\n",
      "features.11.conv_list.2.conv.weight\n",
      "features.11.conv_list.2.bn.weight\n",
      "features.11.conv_list.2.bn.bias\n",
      "features.11.conv_list.2.bn.running_mean\n",
      "features.11.conv_list.2.bn.running_var\n",
      "features.11.conv_list.2.bn.num_batches_tracked\n",
      "features.11.conv_list.3.conv.weight\n",
      "features.11.conv_list.3.bn.weight\n",
      "features.11.conv_list.3.bn.bias\n",
      "features.11.conv_list.3.bn.running_mean\n",
      "features.11.conv_list.3.bn.running_var\n",
      "features.11.conv_list.3.bn.num_batches_tracked\n",
      "features.11.atenchannal2.conv1.weight\n",
      "features.11.conavg_layer.weight\n",
      "features.11.conavg_layer_BN.weight\n",
      "features.11.conavg_layer_BN.bias\n",
      "features.11.conavg_layer_BN.running_mean\n",
      "features.11.conavg_layer_BN.running_var\n",
      "features.11.conavg_layer_BN.num_batches_tracked\n",
      "features.12.conv_list.0.conv.weight\n",
      "features.12.conv_list.0.bn.weight\n",
      "features.12.conv_list.0.bn.bias\n",
      "features.12.conv_list.0.bn.running_mean\n",
      "features.12.conv_list.0.bn.running_var\n",
      "features.12.conv_list.0.bn.num_batches_tracked\n",
      "features.12.conv_list.1.conv.weight\n",
      "features.12.conv_list.1.bn.weight\n",
      "features.12.conv_list.1.bn.bias\n",
      "features.12.conv_list.1.bn.running_mean\n",
      "features.12.conv_list.1.bn.running_var\n",
      "features.12.conv_list.1.bn.num_batches_tracked\n",
      "features.12.conv_list.2.conv.weight\n",
      "features.12.conv_list.2.bn.weight\n",
      "features.12.conv_list.2.bn.bias\n",
      "features.12.conv_list.2.bn.running_mean\n",
      "features.12.conv_list.2.bn.running_var\n",
      "features.12.conv_list.2.bn.num_batches_tracked\n",
      "features.12.conv_list.3.conv.weight\n",
      "features.12.conv_list.3.bn.weight\n",
      "features.12.conv_list.3.bn.bias\n",
      "features.12.conv_list.3.bn.running_mean\n",
      "features.12.conv_list.3.bn.running_var\n",
      "features.12.conv_list.3.bn.num_batches_tracked\n",
      "features.12.atenchannal2.conv1.weight\n",
      "features.12.conavg_layer.weight\n",
      "features.12.conavg_layer_BN.weight\n",
      "features.12.conavg_layer_BN.bias\n",
      "features.12.conavg_layer_BN.running_mean\n",
      "features.12.conavg_layer_BN.running_var\n",
      "features.12.conavg_layer_BN.num_batches_tracked\n",
      "features.13.conv_list.0.conv.weight\n",
      "features.13.conv_list.0.bn.weight\n",
      "features.13.conv_list.0.bn.bias\n",
      "features.13.conv_list.0.bn.running_mean\n",
      "features.13.conv_list.0.bn.running_var\n",
      "features.13.conv_list.0.bn.num_batches_tracked\n",
      "features.13.conv_list.1.conv.weight\n",
      "features.13.conv_list.1.bn.weight\n",
      "features.13.conv_list.1.bn.bias\n",
      "features.13.conv_list.1.bn.running_mean\n",
      "features.13.conv_list.1.bn.running_var\n",
      "features.13.conv_list.1.bn.num_batches_tracked\n",
      "features.13.conv_list.2.conv.weight\n",
      "features.13.conv_list.2.bn.weight\n",
      "features.13.conv_list.2.bn.bias\n",
      "features.13.conv_list.2.bn.running_mean\n",
      "features.13.conv_list.2.bn.running_var\n",
      "features.13.conv_list.2.bn.num_batches_tracked\n",
      "features.13.conv_list.3.conv.weight\n",
      "features.13.conv_list.3.bn.weight\n",
      "features.13.conv_list.3.bn.bias\n",
      "features.13.conv_list.3.bn.running_mean\n",
      "features.13.conv_list.3.bn.running_var\n",
      "features.13.conv_list.3.bn.num_batches_tracked\n",
      "features.13.atenchannal2.conv1.weight\n",
      "features.13.conavg_layer.weight\n",
      "features.13.conavg_layer_BN.weight\n",
      "features.13.conavg_layer_BN.bias\n",
      "features.13.conavg_layer_BN.running_mean\n",
      "features.13.conavg_layer_BN.running_var\n",
      "features.13.conavg_layer_BN.num_batches_tracked\n",
      "features.14.conv_list.0.conv.weight\n",
      "features.14.conv_list.0.bn.weight\n",
      "features.14.conv_list.0.bn.bias\n",
      "features.14.conv_list.0.bn.running_mean\n",
      "features.14.conv_list.0.bn.running_var\n",
      "features.14.conv_list.0.bn.num_batches_tracked\n",
      "features.14.conv_list.1.conv.weight\n",
      "features.14.conv_list.1.bn.weight\n",
      "features.14.conv_list.1.bn.bias\n",
      "features.14.conv_list.1.bn.running_mean\n",
      "features.14.conv_list.1.bn.running_var\n",
      "features.14.conv_list.1.bn.num_batches_tracked\n",
      "features.14.conv_list.2.conv.weight\n",
      "features.14.conv_list.2.bn.weight\n",
      "features.14.conv_list.2.bn.bias\n",
      "features.14.conv_list.2.bn.running_mean\n",
      "features.14.conv_list.2.bn.running_var\n",
      "features.14.conv_list.2.bn.num_batches_tracked\n",
      "features.14.atenchannal2.conv1.weight\n",
      "features.14.conavg_layer.weight\n",
      "features.14.conavg_layer_BN.weight\n",
      "features.14.conavg_layer_BN.bias\n",
      "features.14.conavg_layer_BN.running_mean\n",
      "features.14.conavg_layer_BN.running_var\n",
      "features.14.conavg_layer_BN.num_batches_tracked\n",
      "features.15.conv_list.0.conv.weight\n",
      "features.15.conv_list.0.bn.weight\n",
      "features.15.conv_list.0.bn.bias\n",
      "features.15.conv_list.0.bn.running_mean\n",
      "features.15.conv_list.0.bn.running_var\n",
      "features.15.conv_list.0.bn.num_batches_tracked\n",
      "features.15.conv_list.1.conv.weight\n",
      "features.15.conv_list.1.bn.weight\n",
      "features.15.conv_list.1.bn.bias\n",
      "features.15.conv_list.1.bn.running_mean\n",
      "features.15.conv_list.1.bn.running_var\n",
      "features.15.conv_list.1.bn.num_batches_tracked\n",
      "features.15.conv_list.2.conv.weight\n",
      "features.15.conv_list.2.bn.weight\n",
      "features.15.conv_list.2.bn.bias\n",
      "features.15.conv_list.2.bn.running_mean\n",
      "features.15.conv_list.2.bn.running_var\n",
      "features.15.conv_list.2.bn.num_batches_tracked\n",
      "features.15.conv_list.3.conv.weight\n",
      "features.15.conv_list.3.bn.weight\n",
      "features.15.conv_list.3.bn.bias\n",
      "features.15.conv_list.3.bn.running_mean\n",
      "features.15.conv_list.3.bn.running_var\n",
      "features.15.conv_list.3.bn.num_batches_tracked\n",
      "features.15.atenchannal2.conv1.weight\n",
      "features.15.avd_layer.0.weight\n",
      "features.15.avd_layer.1.weight\n",
      "features.15.avd_layer.1.bias\n",
      "features.15.avd_layer.1.running_mean\n",
      "features.15.avd_layer.1.running_var\n",
      "features.15.avd_layer.1.num_batches_tracked\n",
      "features.15.conavg_layer.weight\n",
      "features.15.conavg_layer_BN.weight\n",
      "features.15.conavg_layer_BN.bias\n",
      "features.15.conavg_layer_BN.running_mean\n",
      "features.15.conavg_layer_BN.running_var\n",
      "features.15.conavg_layer_BN.num_batches_tracked\n",
      "features.16.conv_list.0.conv.weight\n",
      "features.16.conv_list.0.bn.weight\n",
      "features.16.conv_list.0.bn.bias\n",
      "features.16.conv_list.0.bn.running_mean\n",
      "features.16.conv_list.0.bn.running_var\n",
      "features.16.conv_list.0.bn.num_batches_tracked\n",
      "features.16.conv_list.1.conv.weight\n",
      "features.16.conv_list.1.bn.weight\n",
      "features.16.conv_list.1.bn.bias\n",
      "features.16.conv_list.1.bn.running_mean\n",
      "features.16.conv_list.1.bn.running_var\n",
      "features.16.conv_list.1.bn.num_batches_tracked\n",
      "features.16.conv_list.2.conv.weight\n",
      "features.16.conv_list.2.bn.weight\n",
      "features.16.conv_list.2.bn.bias\n",
      "features.16.conv_list.2.bn.running_mean\n",
      "features.16.conv_list.2.bn.running_var\n",
      "features.16.conv_list.2.bn.num_batches_tracked\n",
      "features.16.conv_list.3.conv.weight\n",
      "features.16.conv_list.3.bn.weight\n",
      "features.16.conv_list.3.bn.bias\n",
      "features.16.conv_list.3.bn.running_mean\n",
      "features.16.conv_list.3.bn.running_var\n",
      "features.16.conv_list.3.bn.num_batches_tracked\n",
      "features.16.atenchannal2.conv1.weight\n",
      "features.16.conavg_layer.weight\n",
      "features.16.conavg_layer_BN.weight\n",
      "features.16.conavg_layer_BN.bias\n",
      "features.16.conavg_layer_BN.running_mean\n",
      "features.16.conavg_layer_BN.running_var\n",
      "features.16.conavg_layer_BN.num_batches_tracked\n",
      "features.17.conv_list.0.conv.weight\n",
      "features.17.conv_list.0.bn.weight\n",
      "features.17.conv_list.0.bn.bias\n",
      "features.17.conv_list.0.bn.running_mean\n",
      "features.17.conv_list.0.bn.running_var\n",
      "features.17.conv_list.0.bn.num_batches_tracked\n",
      "features.17.conv_list.1.conv.weight\n",
      "features.17.conv_list.1.bn.weight\n",
      "features.17.conv_list.1.bn.bias\n",
      "features.17.conv_list.1.bn.running_mean\n",
      "features.17.conv_list.1.bn.running_var\n",
      "features.17.conv_list.1.bn.num_batches_tracked\n",
      "features.17.conv_list.2.conv.weight\n",
      "features.17.conv_list.2.bn.weight\n",
      "features.17.conv_list.2.bn.bias\n",
      "features.17.conv_list.2.bn.running_mean\n",
      "features.17.conv_list.2.bn.running_var\n",
      "features.17.conv_list.2.bn.num_batches_tracked\n",
      "features.17.conv_list.3.conv.weight\n",
      "features.17.conv_list.3.bn.weight\n",
      "features.17.conv_list.3.bn.bias\n",
      "features.17.conv_list.3.bn.running_mean\n",
      "features.17.conv_list.3.bn.running_var\n",
      "features.17.conv_list.3.bn.num_batches_tracked\n",
      "features.17.atenchannal2.conv1.weight\n",
      "features.17.conavg_layer.weight\n",
      "features.17.conavg_layer_BN.weight\n",
      "features.17.conavg_layer_BN.bias\n",
      "features.17.conavg_layer_BN.running_mean\n",
      "features.17.conavg_layer_BN.running_var\n",
      "features.17.conavg_layer_BN.num_batches_tracked\n",
      "features.18.conv_list.0.conv.weight\n",
      "features.18.conv_list.0.bn.weight\n",
      "features.18.conv_list.0.bn.bias\n",
      "features.18.conv_list.0.bn.running_mean\n",
      "features.18.conv_list.0.bn.running_var\n",
      "features.18.conv_list.0.bn.num_batches_tracked\n",
      "features.18.conv_list.1.conv.weight\n",
      "features.18.conv_list.1.bn.weight\n",
      "features.18.conv_list.1.bn.bias\n",
      "features.18.conv_list.1.bn.running_mean\n",
      "features.18.conv_list.1.bn.running_var\n",
      "features.18.conv_list.1.bn.num_batches_tracked\n",
      "features.18.conv_list.2.conv.weight\n",
      "features.18.conv_list.2.bn.weight\n",
      "features.18.conv_list.2.bn.bias\n",
      "features.18.conv_list.2.bn.running_mean\n",
      "features.18.conv_list.2.bn.running_var\n",
      "features.18.conv_list.2.bn.num_batches_tracked\n",
      "features.18.conv_list.3.conv.weight\n",
      "features.18.conv_list.3.bn.weight\n",
      "features.18.conv_list.3.bn.bias\n",
      "features.18.conv_list.3.bn.running_mean\n",
      "features.18.conv_list.3.bn.running_var\n",
      "features.18.conv_list.3.bn.num_batches_tracked\n",
      "features.18.atenchannal2.conv1.weight\n",
      "features.18.conavg_layer.weight\n",
      "features.18.conavg_layer_BN.weight\n",
      "features.18.conavg_layer_BN.bias\n",
      "features.18.conavg_layer_BN.running_mean\n",
      "features.18.conavg_layer_BN.running_var\n",
      "features.18.conavg_layer_BN.num_batches_tracked\n",
      "features.19.conv_list.0.conv.weight\n",
      "features.19.conv_list.0.bn.weight\n",
      "features.19.conv_list.0.bn.bias\n",
      "features.19.conv_list.0.bn.running_mean\n",
      "features.19.conv_list.0.bn.running_var\n",
      "features.19.conv_list.0.bn.num_batches_tracked\n",
      "features.19.conv_list.1.conv.weight\n",
      "features.19.conv_list.1.bn.weight\n",
      "features.19.conv_list.1.bn.bias\n",
      "features.19.conv_list.1.bn.running_mean\n",
      "features.19.conv_list.1.bn.running_var\n",
      "features.19.conv_list.1.bn.num_batches_tracked\n",
      "features.19.conv_list.2.conv.weight\n",
      "features.19.conv_list.2.bn.weight\n",
      "features.19.conv_list.2.bn.bias\n",
      "features.19.conv_list.2.bn.running_mean\n",
      "features.19.conv_list.2.bn.running_var\n",
      "features.19.conv_list.2.bn.num_batches_tracked\n",
      "features.19.atenchannal2.conv1.weight\n",
      "features.19.conavg_layer.weight\n",
      "features.19.conavg_layer_BN.weight\n",
      "features.19.conavg_layer_BN.bias\n",
      "features.19.conavg_layer_BN.running_mean\n",
      "features.19.conavg_layer_BN.running_var\n",
      "features.19.conavg_layer_BN.num_batches_tracked\n",
      "conv_last.conv.weight\n",
      "conv_last.bn.weight\n",
      "conv_last.bn.bias\n",
      "conv_last.bn.running_mean\n",
      "conv_last.bn.running_var\n",
      "conv_last.bn.num_batches_tracked\n",
      "fc.weight\n",
      "bn.weight\n",
      "bn.bias\n",
      "bn.running_mean\n",
      "bn.running_var\n",
      "bn.num_batches_tracked\n",
      "linear.weight\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\"/xiaoou/STDC-Seg-master/STDC-Seg-master/checkpoint/train_STDC2-Seg_depthwise14/pths/model_final.pth\")\n",
    "# model_resnet101.load_state_dict({k.replace('module.',''):v for k,v in torch.load(\"densenet169_rnn_fold_1_model_best_f1.pth.tar\")['state_dict'].items()})\n",
    "# state_dict = {key: value for key, value in state_dict.items() if key < 584}\n",
    "model = BiSeNet('STDCNet1446', 19)\n",
    "new_state_dict = {}\n",
    "sub_list = list(state_dict.keys())[:583]\n",
    "for k,v in state_dict.items():\n",
    "    if k in sub_list:\n",
    "        name = k.replace('cp.backbone.','')\n",
    "        new_state_dict[name] = v\n",
    "for k,v in new_state_dict.items():\n",
    "    print(k)\n",
    "# model_resnet101.load_state_dict({k.replace('module.',''):v for k,v in torch.load(\"densenet169_rnn_fold_1_model_best_f1.pth.tar\")['state_dict'].items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.conv.weight\n",
      "features.0.bn.weight\n",
      "features.0.bn.bias\n",
      "features.0.bn.running_mean\n",
      "features.0.bn.running_var\n",
      "features.0.bn.num_batches_tracked\n",
      "features.1.conv.weight\n",
      "features.1.bn.weight\n",
      "features.1.bn.bias\n",
      "features.1.bn.running_mean\n",
      "features.1.bn.running_var\n",
      "features.1.bn.num_batches_tracked\n",
      "features.2.conv_list.0.conv.weight\n",
      "features.2.conv_list.0.bn.weight\n",
      "features.2.conv_list.0.bn.bias\n",
      "features.2.conv_list.0.bn.running_mean\n",
      "features.2.conv_list.0.bn.running_var\n",
      "features.2.conv_list.0.bn.num_batches_tracked\n",
      "features.2.conv_list.1.conv.weight\n",
      "features.2.conv_list.1.bn.weight\n",
      "features.2.conv_list.1.bn.bias\n",
      "features.2.conv_list.1.bn.running_mean\n",
      "features.2.conv_list.1.bn.running_var\n",
      "features.2.conv_list.1.bn.num_batches_tracked\n",
      "features.2.conv_list.2.conv.weight\n",
      "features.2.conv_list.2.bn.weight\n",
      "features.2.conv_list.2.bn.bias\n",
      "features.2.conv_list.2.bn.running_mean\n",
      "features.2.conv_list.2.bn.running_var\n",
      "features.2.conv_list.2.bn.num_batches_tracked\n",
      "features.2.conv_list.3.conv.weight\n",
      "features.2.conv_list.3.bn.weight\n",
      "features.2.conv_list.3.bn.bias\n",
      "features.2.conv_list.3.bn.running_mean\n",
      "features.2.conv_list.3.bn.running_var\n",
      "features.2.conv_list.3.bn.num_batches_tracked\n",
      "features.2.avd_layer.0.weight\n",
      "features.2.avd_layer.1.weight\n",
      "features.2.avd_layer.1.bias\n",
      "features.2.avd_layer.1.running_mean\n",
      "features.2.avd_layer.1.running_var\n",
      "features.2.avd_layer.1.num_batches_tracked\n",
      "features.3.conv_list.0.conv.weight\n",
      "features.3.conv_list.0.bn.weight\n",
      "features.3.conv_list.0.bn.bias\n",
      "features.3.conv_list.0.bn.running_mean\n",
      "features.3.conv_list.0.bn.running_var\n",
      "features.3.conv_list.0.bn.num_batches_tracked\n",
      "features.3.conv_list.1.conv.weight\n",
      "features.3.conv_list.1.bn.weight\n",
      "features.3.conv_list.1.bn.bias\n",
      "features.3.conv_list.1.bn.running_mean\n",
      "features.3.conv_list.1.bn.running_var\n",
      "features.3.conv_list.1.bn.num_batches_tracked\n",
      "features.3.conv_list.2.conv.weight\n",
      "features.3.conv_list.2.bn.weight\n",
      "features.3.conv_list.2.bn.bias\n",
      "features.3.conv_list.2.bn.running_mean\n",
      "features.3.conv_list.2.bn.running_var\n",
      "features.3.conv_list.2.bn.num_batches_tracked\n",
      "features.3.conv_list.3.conv.weight\n",
      "features.3.conv_list.3.bn.weight\n",
      "features.3.conv_list.3.bn.bias\n",
      "features.3.conv_list.3.bn.running_mean\n",
      "features.3.conv_list.3.bn.running_var\n",
      "features.3.conv_list.3.bn.num_batches_tracked\n",
      "features.4.conv_list.0.conv.weight\n",
      "features.4.conv_list.0.bn.weight\n",
      "features.4.conv_list.0.bn.bias\n",
      "features.4.conv_list.0.bn.running_mean\n",
      "features.4.conv_list.0.bn.running_var\n",
      "features.4.conv_list.0.bn.num_batches_tracked\n",
      "features.4.conv_list.1.conv.weight\n",
      "features.4.conv_list.1.bn.weight\n",
      "features.4.conv_list.1.bn.bias\n",
      "features.4.conv_list.1.bn.running_mean\n",
      "features.4.conv_list.1.bn.running_var\n",
      "features.4.conv_list.1.bn.num_batches_tracked\n",
      "features.4.conv_list.2.conv.weight\n",
      "features.4.conv_list.2.bn.weight\n",
      "features.4.conv_list.2.bn.bias\n",
      "features.4.conv_list.2.bn.running_mean\n",
      "features.4.conv_list.2.bn.running_var\n",
      "features.4.conv_list.2.bn.num_batches_tracked\n",
      "features.4.conv_list.3.conv.weight\n",
      "features.4.conv_list.3.bn.weight\n",
      "features.4.conv_list.3.bn.bias\n",
      "features.4.conv_list.3.bn.running_mean\n",
      "features.4.conv_list.3.bn.running_var\n",
      "features.4.conv_list.3.bn.num_batches_tracked\n",
      "features.5.conv_list.0.conv.weight\n",
      "features.5.conv_list.0.bn.weight\n",
      "features.5.conv_list.0.bn.bias\n",
      "features.5.conv_list.0.bn.running_mean\n",
      "features.5.conv_list.0.bn.running_var\n",
      "features.5.conv_list.0.bn.num_batches_tracked\n",
      "features.5.conv_list.1.conv.weight\n",
      "features.5.conv_list.1.bn.weight\n",
      "features.5.conv_list.1.bn.bias\n",
      "features.5.conv_list.1.bn.running_mean\n",
      "features.5.conv_list.1.bn.running_var\n",
      "features.5.conv_list.1.bn.num_batches_tracked\n",
      "features.5.conv_list.2.conv.weight\n",
      "features.5.conv_list.2.bn.weight\n",
      "features.5.conv_list.2.bn.bias\n",
      "features.5.conv_list.2.bn.running_mean\n",
      "features.5.conv_list.2.bn.running_var\n",
      "features.5.conv_list.2.bn.num_batches_tracked\n",
      "features.5.conv_list.3.conv.weight\n",
      "features.5.conv_list.3.bn.weight\n",
      "features.5.conv_list.3.bn.bias\n",
      "features.5.conv_list.3.bn.running_mean\n",
      "features.5.conv_list.3.bn.running_var\n",
      "features.5.conv_list.3.bn.num_batches_tracked\n",
      "features.6.conv_list.0.conv.weight\n",
      "features.6.conv_list.0.bn.weight\n",
      "features.6.conv_list.0.bn.bias\n",
      "features.6.conv_list.0.bn.running_mean\n",
      "features.6.conv_list.0.bn.running_var\n",
      "features.6.conv_list.0.bn.num_batches_tracked\n",
      "features.6.conv_list.1.conv.weight\n",
      "features.6.conv_list.1.bn.weight\n",
      "features.6.conv_list.1.bn.bias\n",
      "features.6.conv_list.1.bn.running_mean\n",
      "features.6.conv_list.1.bn.running_var\n",
      "features.6.conv_list.1.bn.num_batches_tracked\n",
      "features.6.conv_list.2.conv.weight\n",
      "features.6.conv_list.2.bn.weight\n",
      "features.6.conv_list.2.bn.bias\n",
      "features.6.conv_list.2.bn.running_mean\n",
      "features.6.conv_list.2.bn.running_var\n",
      "features.6.conv_list.2.bn.num_batches_tracked\n",
      "features.6.conv_list.3.conv.weight\n",
      "features.6.conv_list.3.bn.weight\n",
      "features.6.conv_list.3.bn.bias\n",
      "features.6.conv_list.3.bn.running_mean\n",
      "features.6.conv_list.3.bn.running_var\n",
      "features.6.conv_list.3.bn.num_batches_tracked\n",
      "features.6.avd_layer.0.weight\n",
      "features.6.avd_layer.1.weight\n",
      "features.6.avd_layer.1.bias\n",
      "features.6.avd_layer.1.running_mean\n",
      "features.6.avd_layer.1.running_var\n",
      "features.6.avd_layer.1.num_batches_tracked\n",
      "features.7.conv_list.0.conv.weight\n",
      "features.7.conv_list.0.bn.weight\n",
      "features.7.conv_list.0.bn.bias\n",
      "features.7.conv_list.0.bn.running_mean\n",
      "features.7.conv_list.0.bn.running_var\n",
      "features.7.conv_list.0.bn.num_batches_tracked\n",
      "features.7.conv_list.1.conv.weight\n",
      "features.7.conv_list.1.bn.weight\n",
      "features.7.conv_list.1.bn.bias\n",
      "features.7.conv_list.1.bn.running_mean\n",
      "features.7.conv_list.1.bn.running_var\n",
      "features.7.conv_list.1.bn.num_batches_tracked\n",
      "features.7.conv_list.2.conv.weight\n",
      "features.7.conv_list.2.bn.weight\n",
      "features.7.conv_list.2.bn.bias\n",
      "features.7.conv_list.2.bn.running_mean\n",
      "features.7.conv_list.2.bn.running_var\n",
      "features.7.conv_list.2.bn.num_batches_tracked\n",
      "features.7.conv_list.3.conv.weight\n",
      "features.7.conv_list.3.bn.weight\n",
      "features.7.conv_list.3.bn.bias\n",
      "features.7.conv_list.3.bn.running_mean\n",
      "features.7.conv_list.3.bn.running_var\n",
      "features.7.conv_list.3.bn.num_batches_tracked\n",
      "features.8.conv_list.0.conv.weight\n",
      "features.8.conv_list.0.bn.weight\n",
      "features.8.conv_list.0.bn.bias\n",
      "features.8.conv_list.0.bn.running_mean\n",
      "features.8.conv_list.0.bn.running_var\n",
      "features.8.conv_list.0.bn.num_batches_tracked\n",
      "features.8.conv_list.1.conv.weight\n",
      "features.8.conv_list.1.bn.weight\n",
      "features.8.conv_list.1.bn.bias\n",
      "features.8.conv_list.1.bn.running_mean\n",
      "features.8.conv_list.1.bn.running_var\n",
      "features.8.conv_list.1.bn.num_batches_tracked\n",
      "features.8.conv_list.2.conv.weight\n",
      "features.8.conv_list.2.bn.weight\n",
      "features.8.conv_list.2.bn.bias\n",
      "features.8.conv_list.2.bn.running_mean\n",
      "features.8.conv_list.2.bn.running_var\n",
      "features.8.conv_list.2.bn.num_batches_tracked\n",
      "features.8.conv_list.3.conv.weight\n",
      "features.8.conv_list.3.bn.weight\n",
      "features.8.conv_list.3.bn.bias\n",
      "features.8.conv_list.3.bn.running_mean\n",
      "features.8.conv_list.3.bn.running_var\n",
      "features.8.conv_list.3.bn.num_batches_tracked\n",
      "features.9.conv_list.0.conv.weight\n",
      "features.9.conv_list.0.bn.weight\n",
      "features.9.conv_list.0.bn.bias\n",
      "features.9.conv_list.0.bn.running_mean\n",
      "features.9.conv_list.0.bn.running_var\n",
      "features.9.conv_list.0.bn.num_batches_tracked\n",
      "features.9.conv_list.1.conv.weight\n",
      "features.9.conv_list.1.bn.weight\n",
      "features.9.conv_list.1.bn.bias\n",
      "features.9.conv_list.1.bn.running_mean\n",
      "features.9.conv_list.1.bn.running_var\n",
      "features.9.conv_list.1.bn.num_batches_tracked\n",
      "features.9.conv_list.2.conv.weight\n",
      "features.9.conv_list.2.bn.weight\n",
      "features.9.conv_list.2.bn.bias\n",
      "features.9.conv_list.2.bn.running_mean\n",
      "features.9.conv_list.2.bn.running_var\n",
      "features.9.conv_list.2.bn.num_batches_tracked\n",
      "features.9.conv_list.3.conv.weight\n",
      "features.9.conv_list.3.bn.weight\n",
      "features.9.conv_list.3.bn.bias\n",
      "features.9.conv_list.3.bn.running_mean\n",
      "features.9.conv_list.3.bn.running_var\n",
      "features.9.conv_list.3.bn.num_batches_tracked\n",
      "features.10.conv_list.0.conv.weight\n",
      "features.10.conv_list.0.bn.weight\n",
      "features.10.conv_list.0.bn.bias\n",
      "features.10.conv_list.0.bn.running_mean\n",
      "features.10.conv_list.0.bn.running_var\n",
      "features.10.conv_list.0.bn.num_batches_tracked\n",
      "features.10.conv_list.1.conv.weight\n",
      "features.10.conv_list.1.bn.weight\n",
      "features.10.conv_list.1.bn.bias\n",
      "features.10.conv_list.1.bn.running_mean\n",
      "features.10.conv_list.1.bn.running_var\n",
      "features.10.conv_list.1.bn.num_batches_tracked\n",
      "features.10.conv_list.2.conv.weight\n",
      "features.10.conv_list.2.bn.weight\n",
      "features.10.conv_list.2.bn.bias\n",
      "features.10.conv_list.2.bn.running_mean\n",
      "features.10.conv_list.2.bn.running_var\n",
      "features.10.conv_list.2.bn.num_batches_tracked\n",
      "features.10.conv_list.3.conv.weight\n",
      "features.10.conv_list.3.bn.weight\n",
      "features.10.conv_list.3.bn.bias\n",
      "features.10.conv_list.3.bn.running_mean\n",
      "features.10.conv_list.3.bn.running_var\n",
      "features.10.conv_list.3.bn.num_batches_tracked\n",
      "features.11.conv_list.0.conv.weight\n",
      "features.11.conv_list.0.bn.weight\n",
      "features.11.conv_list.0.bn.bias\n",
      "features.11.conv_list.0.bn.running_mean\n",
      "features.11.conv_list.0.bn.running_var\n",
      "features.11.conv_list.0.bn.num_batches_tracked\n",
      "features.11.conv_list.1.conv.weight\n",
      "features.11.conv_list.1.bn.weight\n",
      "features.11.conv_list.1.bn.bias\n",
      "features.11.conv_list.1.bn.running_mean\n",
      "features.11.conv_list.1.bn.running_var\n",
      "features.11.conv_list.1.bn.num_batches_tracked\n",
      "features.11.conv_list.2.conv.weight\n",
      "features.11.conv_list.2.bn.weight\n",
      "features.11.conv_list.2.bn.bias\n",
      "features.11.conv_list.2.bn.running_mean\n",
      "features.11.conv_list.2.bn.running_var\n",
      "features.11.conv_list.2.bn.num_batches_tracked\n",
      "features.11.conv_list.3.conv.weight\n",
      "features.11.conv_list.3.bn.weight\n",
      "features.11.conv_list.3.bn.bias\n",
      "features.11.conv_list.3.bn.running_mean\n",
      "features.11.conv_list.3.bn.running_var\n",
      "features.11.conv_list.3.bn.num_batches_tracked\n",
      "features.11.avd_layer.0.weight\n",
      "features.11.avd_layer.1.weight\n",
      "features.11.avd_layer.1.bias\n",
      "features.11.avd_layer.1.running_mean\n",
      "features.11.avd_layer.1.running_var\n",
      "features.11.avd_layer.1.num_batches_tracked\n",
      "features.12.conv_list.0.conv.weight\n",
      "features.12.conv_list.0.bn.weight\n",
      "features.12.conv_list.0.bn.bias\n",
      "features.12.conv_list.0.bn.running_mean\n",
      "features.12.conv_list.0.bn.running_var\n",
      "features.12.conv_list.0.bn.num_batches_tracked\n",
      "features.12.conv_list.1.conv.weight\n",
      "features.12.conv_list.1.bn.weight\n",
      "features.12.conv_list.1.bn.bias\n",
      "features.12.conv_list.1.bn.running_mean\n",
      "features.12.conv_list.1.bn.running_var\n",
      "features.12.conv_list.1.bn.num_batches_tracked\n",
      "features.12.conv_list.2.conv.weight\n",
      "features.12.conv_list.2.bn.weight\n",
      "features.12.conv_list.2.bn.bias\n",
      "features.12.conv_list.2.bn.running_mean\n",
      "features.12.conv_list.2.bn.running_var\n",
      "features.12.conv_list.2.bn.num_batches_tracked\n",
      "features.12.conv_list.3.conv.weight\n",
      "features.12.conv_list.3.bn.weight\n",
      "features.12.conv_list.3.bn.bias\n",
      "features.12.conv_list.3.bn.running_mean\n",
      "features.12.conv_list.3.bn.running_var\n",
      "features.12.conv_list.3.bn.num_batches_tracked\n",
      "features.13.conv_list.0.conv.weight\n",
      "features.13.conv_list.0.bn.weight\n",
      "features.13.conv_list.0.bn.bias\n",
      "features.13.conv_list.0.bn.running_mean\n",
      "features.13.conv_list.0.bn.running_var\n",
      "features.13.conv_list.0.bn.num_batches_tracked\n",
      "features.13.conv_list.1.conv.weight\n",
      "features.13.conv_list.1.bn.weight\n",
      "features.13.conv_list.1.bn.bias\n",
      "features.13.conv_list.1.bn.running_mean\n",
      "features.13.conv_list.1.bn.running_var\n",
      "features.13.conv_list.1.bn.num_batches_tracked\n",
      "features.13.conv_list.2.conv.weight\n",
      "features.13.conv_list.2.bn.weight\n",
      "features.13.conv_list.2.bn.bias\n",
      "features.13.conv_list.2.bn.running_mean\n",
      "features.13.conv_list.2.bn.running_var\n",
      "features.13.conv_list.2.bn.num_batches_tracked\n",
      "features.13.conv_list.3.conv.weight\n",
      "features.13.conv_list.3.bn.weight\n",
      "features.13.conv_list.3.bn.bias\n",
      "features.13.conv_list.3.bn.running_mean\n",
      "features.13.conv_list.3.bn.running_var\n",
      "features.13.conv_list.3.bn.num_batches_tracked\n",
      "conv_last.conv.weight\n",
      "conv_last.bn.weight\n",
      "conv_last.bn.bias\n",
      "conv_last.bn.running_mean\n",
      "conv_last.bn.running_var\n",
      "conv_last.bn.num_batches_tracked\n",
      "fc.weight\n",
      "bn.weight\n",
      "bn.bias\n",
      "bn.running_mean\n",
      "bn.running_var\n",
      "bn.num_batches_tracked\n",
      "linear.weight\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\"/xiaoou/STDC-Seg-master/STDC-Seg-master/STDC-Seg-weight/STDCNet1446_76.47.tar\",map_location='cpu')[\"state_dict\"]\n",
    "model = BiSeNet('STDCNet1446', 19)\n",
    "for k,v in state_dict.items():\n",
    "    print(k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
