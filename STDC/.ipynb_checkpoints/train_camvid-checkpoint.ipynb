{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- encoding: utf-8 -*-\n",
    "from logger import setup_logger\n",
    "from models.model_stages import BiSeNet\n",
    "from cityscapes import CityScapes\n",
    "from loss.loss import OhemCELoss\n",
    "from loss.detail_loss import DetailAggregateLoss\n",
    "from evaluation import MscEvalV0\n",
    "from optimizer_loss import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Unsupported value encountered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parse = argparse.ArgumentParser()\n",
    "    parse.add_argument(\n",
    "            '--local_rank',\n",
    "            dest = 'local_rank',\n",
    "            type = int,\n",
    "            default = -1,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--n_workers_train',\n",
    "            dest = 'n_workers_train',\n",
    "            type = int,\n",
    "            default = 12,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--n_workers_val',\n",
    "            dest = 'n_workers_val',\n",
    "            type = int,\n",
    "            default = 1,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--n_img_per_gpu',\n",
    "            dest = 'n_img_per_gpu',\n",
    "            type = int,\n",
    "            default = 16,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--max_iter',\n",
    "            dest = 'max_iter',\n",
    "            type = int,\n",
    "            default = 60000,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--save_iter_sep',\n",
    "            dest = 'save_iter_sep',\n",
    "            type = int,\n",
    "            default = 1000,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--warmup_steps',\n",
    "            dest = 'warmup_steps',\n",
    "            type = int,\n",
    "            default = 1000,\n",
    "            )      \n",
    "    parse.add_argument(\n",
    "            '--mode',\n",
    "            dest = 'mode',\n",
    "            type = str,\n",
    "            default = 'train',\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--ckpt',\n",
    "            dest = 'ckpt',\n",
    "            type = str,\n",
    "            default = None,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--respath',\n",
    "            dest = 'respath',\n",
    "            type = str,\n",
    "            default = '/xiaoou/STDC-Seg-master/STDC-Seg-master/checkpoint/train_STDC_seg/',\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--backbone',\n",
    "            dest = 'backbone',\n",
    "            type = str,\n",
    "            default = 'STDCNet1446',\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--pretrain_path',\n",
    "            dest = 'pretrain_path',\n",
    "            type = str,\n",
    "            default = '/xiaoou/STDC-Seg-master/STDC-Seg-master/STDC-Seg-weight/STDCNet1446_76.47.tar',\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--use_conv_last',\n",
    "            dest = 'use_conv_last',\n",
    "            type = str2bool,\n",
    "            default = False,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--use_boundary_2',\n",
    "            dest = 'use_boundary_2',\n",
    "            type = str2bool,\n",
    "            default = False,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--use_boundary_4',\n",
    "            dest = 'use_boundary_4',\n",
    "            type = str2bool,\n",
    "            default = False,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--use_boundary_8',\n",
    "            dest = 'use_boundary_8',\n",
    "            type = str2bool,\n",
    "            default = True,\n",
    "            )\n",
    "    parse.add_argument(\n",
    "            '--use_boundary_16',\n",
    "            dest = 'use_boundary_16',\n",
    "            type = str2bool,\n",
    "            default = False,\n",
    "            )\n",
    "    args = parse.parse_args(args=[])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_camvid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import set_cfg_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = argparse.ArgumentParser()\n",
    "parse.add_argument('--config', dest='config', type=str,\n",
    "        default='/xiaoou/STDC-Seg-master/configs/need.py',)\n",
    "parse.add_argument('--finetune-from', type=str, default=None,)\n",
    "\n",
    "args_0 = parse.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = set_cfg_from_file(args_0.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(backbone='STDCNet1446', ckpt=None, local_rank=-1, max_iter=60000, mode='train', n_img_per_gpu=16, n_workers_train=12, n_workers_val=1, pretrain_path='/xiaoou/STDC-Seg-master/STDC-Seg-master/STDC-Seg-weight/STDCNet1446_76.47.tar', respath='/xiaoou/STDC-Seg-master/STDC-Seg-master/checkpoint/train_STDC_seg/', save_iter_sep=200, use_boundary_16=False, use_boundary_2=False, use_boundary_4=False, use_boundary_8=True, use_conv_last=False, warmup_steps=1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(args, val_loader, model):\n",
    "    \"\"\"\n",
    "    args:\n",
    "      val_loader: loaded for validation dataset\n",
    "      model: model\n",
    "    return: mean IoU and IoU class\n",
    "    \"\"\"\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    total_batches = len(val_loader)\n",
    "\n",
    "    data_list = []\n",
    "    for i, (input, label, size, name) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            input_var = Variable(input).cuda()\n",
    "        start_time = time.time()\n",
    "        output = model(input_var)\n",
    "        time_taken = time.time() - start_time\n",
    "        print(\"[%d/%d]  time: %.2f\" % (i + 1, total_batches, time_taken))\n",
    "        output = output.cpu().data[0].numpy()\n",
    "        gt = np.asarray(label[0].numpy(), dtype=np.uint8)\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
    "        data_list.append([gt.flatten(), output.flatten()])\n",
    "\n",
    "    meanIoU, per_class_iu = get_iou(data_list, args.classes)\n",
    "    return meanIoU, per_class_iu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    args = parse_args()\n",
    "    print(args)\n",
    "    save_pth_path = os.path.join(args.respath, 'pths')\n",
    "    dspth = '/xiaoou/my_last_project/dataset/cityscapes'\n",
    "    \n",
    "    # print(save_pth_path)\n",
    "    # print(osp.exists(save_pth_path))\n",
    "    # if not osp.exists(save_pth_path) and dist.get_rank()==0: \n",
    "    if not osp.exists(save_pth_path):\n",
    "        os.makedirs(save_pth_path)\n",
    "    \n",
    "    \n",
    "#     torch.cuda.set_device(args.local_rank)\n",
    "#     dist.init_process_group(\n",
    "#                 backend = 'nccl',\n",
    "#                 init_method = 'tcp://127.0.0.1:33274',\n",
    "#                 world_size = torch.cuda.device_count(),\n",
    "#                 rank=args.local_rank\n",
    "#                 )\n",
    "    \n",
    "    setup_logger(args.respath)\n",
    "    ## dataset\n",
    "    n_classes = 11\n",
    "    n_img_per_gpu = args.n_img_per_gpu\n",
    "    n_workers_train = args.n_workers_train\n",
    "    n_workers_val = args.n_workers_val\n",
    "    use_boundary_16 = args.use_boundary_16\n",
    "    use_boundary_8 = args.use_boundary_8\n",
    "    use_boundary_4 = args.use_boundary_4\n",
    "    use_boundary_2 = args.use_boundary_2\n",
    "    \n",
    "    mode = args.mode\n",
    "    cropsize = [720,960]\n",
    "    randomscale = (0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0, 1.125, 1.25, 1.375, 1.5)\n",
    "\n",
    "#     if dist.get_rank()==0: \n",
    "#         logger.info('n_workers_train: {}'.format(n_workers_train))\n",
    "#         logger.info('n_workers_val: {}'.format(n_workers_val))\n",
    "#         logger.info('use_boundary_2: {}'.format(use_boundary_2))\n",
    "#         logger.info('use_boundary_4: {}'.format(use_boundary_4))\n",
    "#         logger.info('use_boundary_8: {}'.format(use_boundary_8))\n",
    "#         logger.info('use_boundary_16: {}'.format(use_boundary_16))\n",
    "#         logger.info('mode: {}'.format(args.mode))\n",
    "    \n",
    "    \n",
    "#     ds = CityScapes(dspth, cropsize=cropsize, mode=mode, randomscale=randomscale)\n",
    "# #     sampler = torch.utils.data.distributed.DistributedSampler(ds)\n",
    "#     dl = DataLoader(ds,\n",
    "#                     batch_size = n_img_per_gpu,\n",
    "#                     shuffle = False,\n",
    "# #                     sampler = ds,\n",
    "#                     num_workers = n_workers_train,\n",
    "#                     pin_memory = False,\n",
    "#                     drop_last = True)\n",
    "#     # exit(0)\n",
    "#     dsval = CityScapes(dspth, mode='val', randomscale=randomscale)\n",
    "# #     sampler_val = torch.utils.data.distributed.DistributedSampler(dsval)\n",
    "#     dlval = DataLoader(dsval,\n",
    "#                     batch_size = 2,\n",
    "#                     shuffle = False,\n",
    "# #                     sampler = sampler_val,\n",
    "#                     num_workers = n_workers_val,\n",
    "#                     drop_last = False)\n",
    "\n",
    "    ## model\n",
    "    dl = get_camvid_loader.get_data_loader(cfg, mode='train')\n",
    "\n",
    "    dlval = get_camvid_loader.get_data_loader(cfg, mode='val')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ignore_idx = 255\n",
    "    net = BiSeNet(backbone=args.backbone, n_classes=n_classes, pretrain_model=args.pretrain_path, \n",
    "    use_boundary_2=use_boundary_2, use_boundary_4=use_boundary_4, use_boundary_8=use_boundary_8, \n",
    "    use_boundary_16=use_boundary_16, use_conv_last=args.use_conv_last)\n",
    "\n",
    "    if not args.ckpt is None:\n",
    "        net.load_state_dict(torch.load(args.ckpt, map_location='cpu'))\n",
    "    net.cuda()\n",
    "    net.train()\n",
    "#     net = nn.parallel.DistributedDataParallel(net,\n",
    "#             device_ids = [args.local_rank, ],\n",
    "#             output_device = args.local_rank,\n",
    "#             find_unused_parameters=True\n",
    "#             )\n",
    "\n",
    "    score_thres = 0.7\n",
    "    n_min = n_img_per_gpu*cropsize[0]*cropsize[1]//16\n",
    "    criteria_p = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)\n",
    "    criteria_16 = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)\n",
    "    criteria_32 = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)\n",
    "    boundary_loss_func = DetailAggregateLoss()\n",
    "    ## optimizer\n",
    "    maxmIOU50 = 0.\n",
    "    maxmIOU75 = 0.\n",
    "    momentum = 0.9\n",
    "    weight_decay = 5e-4\n",
    "    lr_start = 1e-2\n",
    "    max_iter = args.max_iter\n",
    "    save_iter_sep = args.save_iter_sep\n",
    "    power = 0.9\n",
    "    warmup_steps = args.warmup_steps\n",
    "    warmup_start_lr = 1e-5\n",
    "\n",
    "#     if dist.get_rank()==0: \n",
    "#         print('max_iter: ', max_iter)\n",
    "#         print('save_iter_sep: ', save_iter_sep)\n",
    "#         print('warmup_steps: ', warmup_steps)\n",
    "    optim = Optimizer(\n",
    "#             model = net.module,\n",
    "            model = net,\n",
    "            loss = boundary_loss_func,\n",
    "            lr0 = lr_start,\n",
    "            momentum = momentum,\n",
    "            wd = weight_decay,\n",
    "            warmup_steps = warmup_steps,\n",
    "            warmup_start_lr = warmup_start_lr,\n",
    "            max_iter = max_iter,\n",
    "            power = power)\n",
    "    \n",
    "    ## train loop\n",
    "    msg_iter = 50\n",
    "    loss_avg = []\n",
    "    loss_boundery_bce = []\n",
    "    loss_boundery_dice = []\n",
    "    st = glob_st = time.time()\n",
    "    diter = iter(dl)\n",
    "    epoch = 0\n",
    "    for it in range(max_iter):\n",
    "        try:\n",
    "            im, lb = next(diter)\n",
    "            if not im.size()[0]==n_img_per_gpu: raise StopIteration\n",
    "        except StopIteration:\n",
    "            epoch += 1\n",
    "#             sampler.set_epoch(epoch)\n",
    "            diter = iter(dl)\n",
    "            im, lb = next(diter)\n",
    "        im = im.cuda()\n",
    "        lb = lb.cuda()\n",
    "        H, W = im.size()[2:]\n",
    "        lb = torch.squeeze(lb, 1)\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "\n",
    "        if use_boundary_2 and use_boundary_4 and use_boundary_8:\n",
    "            out, out16, out32, detail2, detail4, detail8 = net(im)\n",
    "        \n",
    "        if (not use_boundary_2) and use_boundary_4 and use_boundary_8:\n",
    "            out, out16, out32, detail4, detail8 = net(im)\n",
    "\n",
    "        if (not use_boundary_2) and (not use_boundary_4) and use_boundary_8:\n",
    "            out, out16, out32, detail8 = net(im)\n",
    "\n",
    "        if (not use_boundary_2) and (not use_boundary_4) and (not use_boundary_8):\n",
    "            out, out16, out32 = net(im)\n",
    "\n",
    " \n",
    "        \n",
    "        lossp = criteria_p(out, lb.long())\n",
    "        loss2 = criteria_16(out16, lb.long())\n",
    "        loss3 = criteria_32(out32, lb.long())\n",
    "        \n",
    "        boundery_bce_loss = 0.\n",
    "        boundery_dice_loss = 0.\n",
    "        \n",
    "        \n",
    "        if use_boundary_2: \n",
    "            # if dist.get_rank()==0:\n",
    "            #     print('use_boundary_2')\n",
    "            boundery_bce_loss2,  boundery_dice_loss2 = boundary_loss_func(detail2, lb)\n",
    "            boundery_bce_loss += boundery_bce_loss2\n",
    "            boundery_dice_loss += boundery_dice_loss2\n",
    "        \n",
    "        if use_boundary_4:\n",
    "            # if dist.get_rank()==0:\n",
    "            #     print('use_boundary_4')\n",
    "            boundery_bce_loss4,  boundery_dice_loss4 = boundary_loss_func(detail4, lb)\n",
    "            boundery_bce_loss += boundery_bce_loss4\n",
    "            boundery_dice_loss += boundery_dice_loss4\n",
    "\n",
    "        if use_boundary_8:\n",
    "            # if dist.get_rank()==0:\n",
    "            #     print('use_boundary_8')\n",
    "            boundery_bce_loss8,  boundery_dice_loss8 = boundary_loss_func(detail8, lb)\n",
    "            boundery_bce_loss += boundery_bce_loss8\n",
    "            boundery_dice_loss += boundery_dice_loss8\n",
    "\n",
    "        loss = lossp + loss2 + loss3 + boundery_bce_loss + boundery_dice_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loss_avg.append(loss.item())\n",
    "\n",
    "        loss_boundery_bce.append(boundery_bce_loss.item())\n",
    "        loss_boundery_dice.append(boundery_dice_loss.item())\n",
    "\n",
    "        ## print training log message\n",
    "        if (it+1)%msg_iter==0:\n",
    "            loss_avg = sum(loss_avg) / len(loss_avg)\n",
    "            lr = optim.lr\n",
    "            ed = time.time()\n",
    "            t_intv, glob_t_intv = ed - st, ed - glob_st\n",
    "            eta = int((max_iter - it) * (glob_t_intv / it))\n",
    "            eta = str(datetime.timedelta(seconds=eta))\n",
    "\n",
    "            loss_boundery_bce_avg = sum(loss_boundery_bce) / len(loss_boundery_bce)\n",
    "            loss_boundery_dice_avg = sum(loss_boundery_dice) / len(loss_boundery_dice)\n",
    "            msg = ', '.join([\n",
    "                'it: {it}/{max_it}',\n",
    "                'lr: {lr:4f}',\n",
    "                'loss: {loss:.4f}',\n",
    "                'boundery_bce_loss: {boundery_bce_loss:.4f}',\n",
    "                'boundery_dice_loss: {boundery_dice_loss:.4f}',\n",
    "                'eta: {eta}',\n",
    "                'time: {time:.4f}',\n",
    "            ]).format(\n",
    "                it = it+1,\n",
    "                max_it = max_iter,\n",
    "                lr = lr,\n",
    "                loss = loss_avg,\n",
    "                boundery_bce_loss = loss_boundery_bce_avg,\n",
    "                boundery_dice_loss = loss_boundery_dice_avg,\n",
    "                time = t_intv,\n",
    "                eta = eta\n",
    "            )\n",
    "            \n",
    "            logger.info(msg)\n",
    "            loss_avg = []\n",
    "            loss_boundery_bce = []\n",
    "            loss_boundery_dice = []\n",
    "            st = ed\n",
    "            # print(boundary_loss_func.get_params())\n",
    "        if (it+1)%save_iter_sep==0:# and it != 0:\n",
    "            \n",
    "            ## model\n",
    "            logger.info('evaluating the model ...')\n",
    "            logger.info('setup and restore model')\n",
    "            \n",
    "            net.eval()\n",
    "\n",
    "            # ## evaluator\n",
    "            logger.info('compute the mIOU')\n",
    "            with torch.no_grad():\n",
    "                single_scale1 = MscEvalV0()\n",
    "                mIOU50 = single_scale1(net, dlval, n_classes)\n",
    "\n",
    "                single_scale2= MscEvalV0(scale=0.75)\n",
    "                mIOU75 = single_scale2(net, dlval, n_classes)\n",
    "\n",
    "\n",
    "            save_pth = osp.join(save_pth_path, 'model_iter{}_mIOU50_{}_mIOU75_{}.pth'\n",
    "            .format(it+1, str(round(mIOU50,4)), str(round(mIOU75,4))))\n",
    "            \n",
    "            state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()\n",
    "#             if dist.get_rank()==0: \n",
    "            torch.save(state, save_pth)\n",
    "\n",
    "            logger.info('training iteration {}, model saved to: {}'.format(it+1, save_pth))\n",
    "\n",
    "            if mIOU50 > maxmIOU50:\n",
    "                maxmIOU50 = mIOU50\n",
    "                save_pth = osp.join(save_pth_path, 'model_maxmIOU50.pth'.format(it+1))\n",
    "                state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()\n",
    "#                 if dist.get_rank()==0: \n",
    "                torch.save(state, save_pth)\n",
    "                    \n",
    "                logger.info('max mIOU model saved to: {}'.format(save_pth))\n",
    "            \n",
    "            if mIOU75 > maxmIOU75:\n",
    "                maxmIOU75 = mIOU75\n",
    "                save_pth = osp.join(save_pth_path, 'model_maxmIOU75.pth'.format(it+1))\n",
    "                state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()\n",
    "#                 if dist.get_rank()==0: \n",
    "                torch.save(state, save_pth)\n",
    "                logger.info('max mIOU model saved to: {}'.format(save_pth))\n",
    "            \n",
    "            logger.info('mIOU50 is: {}, mIOU75 is: {}'.format(mIOU50, mIOU75))\n",
    "            logger.info('maxmIOU50 is: {}, maxmIOU75 is: {}.'.format(maxmIOU50, maxmIOU75))\n",
    "\n",
    "            net.train()\n",
    "    \n",
    "    ## dump the final model\n",
    "    save_pth = osp.join(save_pth_path, 'model_final.pth')\n",
    "    net.cpu()\n",
    "    state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()\n",
    "#     if dist.get_rank()==0: \n",
    "    torch.save(state, save_pth)\n",
    "    logger.info('training done, model saved to: {}'.format(save_pth))\n",
    "    print('epoch: ', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(backbone='STDCNet1446', ckpt=None, local_rank=-1, max_iter=60000, mode='train', n_img_per_gpu=16, n_workers_train=12, n_workers_val=1, pretrain_path='/xiaoou/STDC-Seg-master/STDC-Seg-master/STDC-Seg-weight/STDCNet1446_76.47.tar', respath='/xiaoou/STDC-Seg-master/STDC-Seg-master/checkpoint/train_STDC_seg/', save_iter_sep=200, use_boundary_16=False, use_boundary_2=False, use_boundary_4=False, use_boundary_8=True, use_conv_last=False, warmup_steps=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/xiaoou/STDC-Seg-master/STDC-Seg-master/models/model_stages.py:129: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W.weight, 0)\n",
      "/xiaoou/STDC-Seg-master/STDC-Seg-master/models/model_stages.py:130: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W.bias, 0)\n",
      "it: 50/60000, lr: 0.000014, loss: 8.6211, boundery_bce_loss: 0.7505, boundery_dice_loss: 0.9169, eta: 2 days, 2:25:42, time: 148.3808\n",
      "it: 100/60000, lr: 0.000020, loss: 7.8660, boundery_bce_loss: 0.6032, boundery_dice_loss: 0.9094, eta: 2 days, 1:26:43, time: 145.8107\n",
      "it: 150/60000, lr: 0.000028, loss: 7.2748, boundery_bce_loss: 0.4759, boundery_dice_loss: 0.9033, eta: 2 days, 1:36:27, time: 150.4059\n",
      "it: 200/60000, lr: 0.000040, loss: 6.8514, boundery_bce_loss: 0.3716, boundery_dice_loss: 0.8976, eta: 2 days, 1:47:07, time: 151.8172\n",
      "evaluating the model ...\n",
      "setup and restore model\n",
      "compute the mIOU\n",
      "100%|██████████| 51/51 [00:03<00:00, 14.18it/s]\n",
      "100%|██████████| 51/51 [00:03<00:00, 14.84it/s]\n",
      "training iteration 200, model saved to: /xiaoou/STDC-Seg-master/STDC-Seg-master/checkpoint/train_STDC_seg/pths/model_iter200_mIOU50_0.1345_mIOU75_0.1128.pth\n",
      "max mIOU model saved to: /xiaoou/STDC-Seg-master/STDC-Seg-master/checkpoint/train_STDC_seg/pths/model_maxmIOU75.pth\n",
      "mIOU50 is: 0.13454480469226837, mIOU75 is: 0.11283668130636215\n",
      "maxmIOU50 is: 0.0, maxmIOU75 is: 0.11283668130636215.\n",
      "it: 250/60000, lr: 0.000056, loss: 6.4804, boundery_bce_loss: 0.2954, boundery_dice_loss: 0.8906, eta: 2 days, 3:12:32, time: 171.8366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-14de8cc92c86>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mditer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mn_img_per_gpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-daa3273de397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-14de8cc92c86>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;31m#             sampler.set_epoch(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mditer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mditer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
